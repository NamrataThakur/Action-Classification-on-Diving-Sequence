{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3593e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.6.0\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grace\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.scimath import sqrt # used for hoF\n",
    "from numpy import arctan2 # used for hoF\n",
    "\n",
    "from scipy import pi, cos, sin # used for HoF\n",
    "from scipy.ndimage import uniform_filter # used for hoF\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "#for i3d extraction\n",
    "from models.i3d.extract_i3d import ExtractI3D\n",
    "from utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3835b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "dive_action_labels  = ['Entry', 'Flight', 'Takeoff']\n",
    "temp_segment_model = None\n",
    "autoscore_model = None\n",
    "ss_twist_classifier_model = None\n",
    "somersault_model = None\n",
    "twist_model = None\n",
    "angle_of_entry_model = None\n",
    "splash_model = None\n",
    "linear_regression_model = None\n",
    "folderpath      = 'modelcheckpoints/'\n",
    "\n",
    "#i3d variables\n",
    "i3dextractor = None\n",
    "stack_size = 12\n",
    "step_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a7d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temporal_segment_model():\n",
    "    print('loading temporal segment model')\n",
    "    global temp_segment_model\n",
    "    image_height, image_width = 64, 64\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    model.load_weights(folderpath+\"model_2D.h5\")\n",
    "    temp_segment_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc672abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_autoscore_model():\n",
    "    print('loading autoscore model')\n",
    "    global autoscore_model\n",
    "    if (autoscore_model == None):\n",
    "        autoscore_model = load_model('modelcheckpoints/fullyconnected_ID256D48D1_0.1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f1eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ss_twist_classifier_model():\n",
    "    print('loading ss_twist_classifier model')\n",
    "    global ss_twist_classifier_model\n",
    "    image_height, image_width = 64, 64\n",
    "    optim = tf.keras.optimizers.Adam(0.0001)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=optim, metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    model.load_weights(folderpath+\"model_flightClassify_2D_3.h5\")\n",
    "    ss_twist_classifier_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b44ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_somersault_model():\n",
    "    print('loading somersault model')\n",
    "    global somersault_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc1b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twist_model():\n",
    "    print('loading twist model')\n",
    "    global twist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b61b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_angle_of_entry_model():\n",
    "    print('loading angle of entry model')\n",
    "    global angle_of_entry_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7781db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_splash_model():\n",
    "    print('loading splash model')\n",
    "    global splash_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9753b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linear_regression_model():\n",
    "    print('loading linear regression model')\n",
    "    global linear_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ceb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureDirectoryClean(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    else:\n",
    "        for f in os.listdir(dirpath):\n",
    "            os.remove(os.path.join(dirpath, f))\n",
    "\n",
    "def extractFolderAndFileNameFromAbsPath(absFilePath):\n",
    "    filename_sep = absFilePath.rindex('\\\\')\n",
    "    extension_sep = absFilePath.rindex(\".\")\n",
    "    folder = absFilePath[0: filename_sep]\n",
    "    shortfilename = absFilePath[filename_sep+1:extension_sep]\n",
    "    ext = absFilePath[extension_sep+1:len(absFilePath)]\n",
    "    return folder, shortfilename, ext\n",
    "\n",
    "def extractEventNoAndDiveNo(folderPath):\n",
    "    tokens = folderPath.split(\"\\\\\")\n",
    "    diveno = tokens[len(tokens)-1]\n",
    "    eventno = tokens[len(tokens)-2]\n",
    "    return eventno, diveno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7121b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_temporal_segmentation(vidpath, imgOutputDir):\n",
    "    global temp_segment_model\n",
    "    window_size=3\n",
    "    predicted_label_list = []\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    " \n",
    "    video_reader = cv2.VideoCapture(vidpath)\n",
    " \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    for dive_action_label in dive_action_labels:\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        ensureDirectoryClean(subdir)\n",
    "    \n",
    "    #video_writer = cv2.VideoWriter(imgOutputDir, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (original_video_width, original_video_height))\n",
    "    count_seg=0\n",
    "    image_height, image_width = 64, 64\n",
    "    while True: \n",
    "        count_seg += 1 \n",
    "        status, frame = video_reader.read() \n",
    " \n",
    "        if not status:\n",
    "            break\n",
    "         \n",
    "        # predict frame type (Takeoff/Flight/Entry)\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255 \n",
    "        predicted_labels_probabilities = temp_segment_model.predict(np.expand_dims(normalized_frame, axis = 0))[0] \n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    " \n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "            #print('predicted_labels_probabilities_np : ',predicted_labels_probabilities_np)\n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "            #print('predicted_labels_probabilities_averaged',predicted_labels_probabilities_averaged)\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "            \n",
    "        else: # len(predicted_labels_probabilities_deque) < window_size\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities) \n",
    "        \n",
    "        predicted_label_list.append(predicted_label)\n",
    "        predicted_class_name = dive_action_labels[predicted_label]\n",
    "        #print('predicted_class' , predicted_class_name)\n",
    "        \n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ predicted_class_name \n",
    "        imagename = subdir+\"\\\\\"+(\"frame%04d.jpg\" % count_seg)\n",
    "        #print('write to ', imagename)\n",
    "        cv2.imwrite(imagename, frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    #video_writer.release()\n",
    "    return predicted_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13167e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizeFrameDim [width, height]\n",
    "def createVideo(image_folder, video_folder, divephase, vidname, resizeFrame=False, resizeFrameDim=[64,64]):\n",
    "    images = []\n",
    "    #folders = [image_folder+\"\\\\Ntakeoff\", image_folder+\"\\\\Nflight\", image_folder+\"\\\\Nentry\"]\n",
    "    subfolder_images = sorted(os.listdir(image_folder))\n",
    "    for subfolder_image in subfolder_images:\n",
    "        if subfolder_image.endswith(\".jpg\"):\n",
    "            images.append(image_folder+\"\\\\\"+subfolder_image)\n",
    "    if (len(images)==0):\n",
    "        return\n",
    "    \n",
    "    frame = cv2.imread(images[0])\n",
    "\n",
    "    height, width, layers = frame.shape\n",
    "    if (resizeFrame == True):\n",
    "        height = resizeFrameDim[1]\n",
    "        width = resizeFrameDim[0]\n",
    "    vidFullName = video_folder+'\\\\'+vidname+\"_\"+divephase+\".mp4\"\n",
    "    print('writing video to ', vidFullName , ' framewidth ', width, ' frameheight ', height)\n",
    "    fps = 25\n",
    "    video = cv2.VideoWriter(vidFullName, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (width,height))\n",
    "\n",
    "    \n",
    "    for image in images:\n",
    "        frame = cv2.imread(image)\n",
    "        if (resizeFrame == True):\n",
    "            frame = cv2.resize(frame, (height, width))\n",
    "        video.write(frame)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    return vidFullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3209b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleanUp flag to delete temp folder created for normalizing number of images\n",
    "def createNormalizedVideos(vidpath, imgOutputDir, numImages, cleanUp=True):\n",
    "    video_list = []\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    subdirNorm = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\N_all\" \n",
    "    ensureDirectoryClean(subdirNorm)\n",
    "    count_norm = 0\n",
    "    for dive_action_label in ['Takeoff', 'Flight', 'Entry']: #Need to redefine the oder instead of using dive_action_label\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        index = {}\n",
    "        files = os.listdir(subdir)\n",
    "        numFiles = len(files)\n",
    "        if (numFiles == 0):\n",
    "            os.rmdir(subdirNorm)\n",
    "            continue\n",
    "        for file in files:\n",
    "            index[file] = 1\n",
    "        if (numFiles < numImages):\n",
    "            diff = numImages - numFiles\n",
    "            count_diff = 0;\n",
    "            while (count_diff < diff):\n",
    "                rand = random.choice(files)\n",
    "                index[rand] = index[rand]+1\n",
    "                count_diff += 1\n",
    "            \n",
    "        elif (numFiles > numImages):\n",
    "            diff = numFiles - numImages\n",
    "            count_diff = 0;\n",
    "            while (count_diff < diff):\n",
    "                rand = random.choice(files)\n",
    "                if (index[rand] > 0):\n",
    "                    index[rand] = index[rand]-1\n",
    "                    count_diff += 1\n",
    "        sortedkeys = list(index.keys())\n",
    "        sortedkeys.sort()\n",
    "        #count = 0\n",
    " \n",
    "        for key in sortedkeys:\n",
    "            frame = cv2.imread(subdir+\"\\\\\"+key)\n",
    "            for i in range(index[key]):\n",
    "                count_norm +=1\n",
    "                imagename = subdirNorm+\"\\\\\"+(\"frame%04d.jpg\" % count_norm)\n",
    "                cv2.imwrite(imagename, frame)\n",
    "    #write video to directory\n",
    "    imgInputDir = imgOutputDir+\"\\\\\"+shortfilename+ \"\\\\\"+ \"N_all\"\n",
    "    vidFullName = createVideo(imgInputDir, imgOutputDir+\"\\\\\"+shortfilename, \"N_all\", shortfilename,\n",
    "                             resizeFrame=True, resizeFrameDim=[64,64])\n",
    "    video_list.append(vidFullName)\n",
    "        \n",
    "    #cleanup\n",
    "    if(cleanUp == True):\n",
    "        for f in os.listdir(subdirNorm):\n",
    "            os.remove(subdirNorm+\"\\\\\"+f)\n",
    "        os.rmdir(subdirNorm) \n",
    "            \n",
    "    return video_list\n",
    "#createNormalizedVideos(\".\\\\uploads\\\\01_10_all.mp4\", '.\\\\images', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afab8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videosAreComplete(vidpath, imgOutputDir):\n",
    "    hasTakeoff = False\n",
    "    hasFlight = False\n",
    "    hasEntry = False\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    print (imgOutputDir, ' === ' , shortfilename)\n",
    "    print('tkoff files ', getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Takeoff\"))\n",
    "    print('Flight files ', getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Flight\"))\n",
    "    print('Entry files ', getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Entry\"))\n",
    "    \n",
    "    if (getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Takeoff\") > 0):\n",
    "        hasTakeoff = True\n",
    "    else:\n",
    "        print('Error: No Takeoff files!')\n",
    "        \n",
    "    if (getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Flight\") > 0):\n",
    "        hasFlight = True\n",
    "    else:\n",
    "        print('Error: No Flight files!')\n",
    "        \n",
    "    if (getNumFiles(imgOutputDir+\"\\\\\" + shortfilename+\"\\\\Entry\") > 0):\n",
    "        hasEntry = True\n",
    "    else:\n",
    "        print('Error: No Entry files!')\n",
    "    \n",
    "    return hasTakeoff and hasFlight and hasEntry\n",
    "\n",
    "def getNumFiles(folderpath):\n",
    "    return len([f for f in os.listdir(folderpath)  if f.endswith('.jpg') and os.path.isfile(os.path.join(folderpath, f))])\n",
    "\n",
    "\n",
    "#videosAreComplete = videosAreComplete(\".\\\\uploads\\\\01_10_all.mp4\", \".\\\\images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9561a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractI3DFeatures(vidpaths):\n",
    "    global i3dextractor, stack_size, step_size\n",
    "    if (i3dextractor == None):\n",
    "        args = OmegaConf.load(build_cfg_path('i3d'))\n",
    "        args.stack_size = stack_size\n",
    "        args.step_size = step_size\n",
    "        args.extraction_fps = 25\n",
    "        args.device='cpu'#force to cpu to prevent OOM error\n",
    "        args.flow_type = 'raft' # 'pwc' is not supported on Google Colab (cupy version mismatch)\n",
    "        i3dextractor = ExtractI3D(args)\n",
    "    rgb_features = [] \n",
    "    for vidpath in vidpaths:\n",
    "        print(f'I3D Extracting for {vidpath}')\n",
    "        feature_dict = i3dextractor.extract(vidpath)\n",
    "        vidname = vidpath.replace('.mp4','')\n",
    "        for k, v in feature_dict.items():\n",
    "            if (k=='rgb'): # or k=='flow'):\n",
    "                rgb_features.append(v)\n",
    "    i3d_features = np.concatenate(rgb_features, axis=None)\n",
    "    numWindows = (96-stack_size)/step_size\n",
    "    return i3d_features.reshape(1, int(numWindows*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7344dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_autoscore(vidpath, imgOutputDir):\n",
    "    print('predict autoscore')\n",
    "    global autoscore_model\n",
    "    # check that there are 3 videos, else decline to proceed\n",
    "    if (videosAreComplete(vidpath, imgOutputDir)==False):\n",
    "        print('videos are incomplete! missing either entry, flight or takeoff phase')\n",
    "        return -1\n",
    "    numImages=32\n",
    "    norm_vidpaths = createNormalizedVideos(vidpath, imgOutputDir, numImages)\n",
    "\n",
    "    videos_features = extractI3DFeatures(norm_vidpaths)\n",
    "    score = autoscore_model.predict(videos_features)[0][0]\n",
    "    for video in norm_vidpaths:\n",
    "        os.remove(video)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a851b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ss_or_twist(imgFolder):\n",
    "    print('predict ss or twist')\n",
    "    global ss_twist_classifier_model\n",
    "    window_size = 3\n",
    "    images = sorted(os.listdir(imgFolder))\n",
    "    predicted_label_list = []\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "    eventno, diveno = extractEventNoAndDiveNo(imgFolder)\n",
    "    numTwistFrames = 0\n",
    "    numSSFrames = 0\n",
    "    fps = 25\n",
    "    frame = cv2.imread(imgFolder+\"\\\\\"+images[0])\n",
    "    image_height = frame.shape[0]\n",
    "    image_width = frame.shape[1]\n",
    "    videoSS = cv2.VideoWriter(imgFolder+eventno+\"_\"+diveno+\"_ss.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (image_width,image_height))\n",
    "    videoTW = cv2.VideoWriter(imgFolder+eventno+\"_\"+diveno+\"_tw.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (image_width,image_height))\n",
    "    for i in range(len(images)):\n",
    "        frame = cv2.imread(imgFolder+\"\\\\\"+images[i])\n",
    "        \n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (64,64))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    " \n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = ss_twist_classifier_model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    " \n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    " \n",
    "        # Assuring that the Deque is completely filled before starting the averaging process\n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    " \n",
    "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "            #print('predicted_labels_probabilities_np : ',predicted_labels_probabilities_np)\n",
    " \n",
    "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "            #print('predicted_labels_probabilities_averaged',predicted_labels_probabilities_averaged)\n",
    " \n",
    "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    " \n",
    "        else: # len(predicted_labels_probabilities_deque) < window_size\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities) \n",
    " \n",
    "\n",
    "        # Accessing The Class Name using predicted label.\n",
    "        #predicted_class_name = dive_action_labels[predicted_label]\n",
    "        \n",
    "        if (predicted_label == 0): #SS\n",
    "            numSSFrames += 1\n",
    "            videoSS.write(frame)\n",
    "            predicted_label_list.append('SS')\n",
    "        elif (predicted_label == 1):\n",
    "            numTwistFrames += 1\n",
    "            videoTW.write(frame)\n",
    "            predicted_label_list.append('TW')\n",
    "    print('numSSFrames ', numSSFrames)\n",
    "    print('numTwistFrames ', numTwistFrames)\n",
    "    print(predicted_label_list)\n",
    "    cv2.destroyAllWindows()\n",
    "    videoSS.release()\n",
    "    videoTW.release()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8686d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_somersaults(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cbae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_twists(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d07001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_angle_of_entry(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f50c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_splash_index(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aae1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d589b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processVideo(vidpath):\n",
    "    print('processing ', vidpath)\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    predict_temporal_segmentation(vidpath, '.\\\\images')\n",
    "    autoscore = predict_autoscore(vidpath, '.\\\\images')\n",
    "    predict_ss_or_twist(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    numSomersaults = predict_num_somersaults(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    numTwists = predict_num_twists(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    angleOfEntry = predict_angle_of_entry(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    splashIndex = predict_splash_index(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    final_score = predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex)\n",
    "    print('autoscore: ', autoscore, \n",
    "          ', numSomersaults: ', numSomersaults, \n",
    "          ', numTwists: ', numTwists,\n",
    "          ', angleOfEntry: ', angleOfEntry,\n",
    "          ', splashIndex: ', splashIndex,\n",
    "          ', final_score: ', final_score)\n",
    "    return final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a3669c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_temporal_segment_model()\n",
    "    load_autoscore_model()\n",
    "    load_ss_twist_classifier_model()\n",
    "    load_somersault_model()\n",
    "    load_twist_model()\n",
    "    load_angle_of_entry_model()\n",
    "    load_splash_model()\n",
    "    load_linear_regression_model()\n",
    "    #final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex = processVideo(\".\\\\testdive5.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b9b6731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading temporal segment model\n",
      "loading autoscore model\n",
      "loading ss_twist_classifier model\n",
      "loading somersault model\n",
      "loading twist model\n",
      "loading angle of entry model\n",
      "loading splash model\n",
      "loading linear regression model\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48595aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  .\\uploads\\01_100_all.mp4\n",
      "predict autoscore\n",
      ".\\images  ===  01_100_all\n",
      "tkoff files  33\n",
      "Flight files  30\n",
      "Entry files  33\n",
      "writing video to  .\\images\\01_100_all\\01_100_all_N_all.mp4  framewidth  64  frameheight  64\n",
      "using device  cpu\n",
      "I3D Extracting for .\\images\\01_100_all\\01_100_all_N_all.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grace\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict ss or twist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [30/Apr/2023 23:04:23] \"POST /videoupload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numSSFrames  30\n",
      "numTwistFrames  0\n",
      "['SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS']\n",
      "autoscore:  0.6137163 , numSomersaults:  -1 , numTwists:  -1 , angleOfEntry:  -1 , splashIndex:  -1 , final_score:  -1\n",
      "result {\"file\": \"01_100_all.mp4\", \"final_score\": \"-1\", \"autoscore\": \"0.6137163\", \"numSomersaults\": \"-1\", \"numTwists\": \"-1\", \"angleOfEntry\": \"-1\", \"splashIndex\": \"-1\"}\n",
      "processing  .\\uploads\\testdive5.mp4\n",
      "predict autoscore\n",
      ".\\images  ===  testdive5\n",
      "tkoff files  29\n",
      "Flight files  82\n",
      "Entry files  35\n",
      "writing video to  .\\images\\testdive5\\testdive5_N_all.mp4  framewidth  64  frameheight  64\n",
      "I3D Extracting for .\\images\\testdive5\\testdive5_N_all.mp4\n",
      "predict ss or twist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [30/Apr/2023 23:16:11] \"POST /videoupload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numSSFrames  53\n",
      "numTwistFrames  29\n",
      "['TW', 'TW', 'TW', 'TW', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'TW', 'TW', 'TW', 'SS', 'SS', 'SS', 'TW', 'SS', 'SS', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'TW', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS', 'SS']\n",
      "autoscore:  0.62222165 , numSomersaults:  -1 , numTwists:  -1 , angleOfEntry:  -1 , splashIndex:  -1 , final_score:  -1\n",
      "result {\"file\": \"testdive5.mp4\", \"final_score\": \"-1\", \"autoscore\": \"0.62222165\", \"numSomersaults\": \"-1\", \"numTwists\": \"-1\", \"angleOfEntry\": \"-1\", \"splashIndex\": \"-1\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from flask import Flask, flash, request, redirect, url_for, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from werkzeug.wrappers import Request, Response\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = \"secret key\"\n",
    "app.config['UPLOAD_FOLDER'] = '.\\\\uploads\\\\'\n",
    "\n",
    "@app.route('/videoupload', methods=['POST'])\n",
    "def upload_video():\n",
    "    if 'file' not in request.files:\n",
    "        return {\"error\" : \"no file in request\"}\n",
    "    file = request.files['file']\n",
    "    filename = secure_filename(file.filename)\n",
    "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "    final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex = processVideo(app.config['UPLOAD_FOLDER']+filename)\n",
    "    \n",
    "    result = {\n",
    "        \"file\" : file.filename,\n",
    "        \"final_score\" : str(final_score),\n",
    "        \"autoscore\" : str(autoscore),\n",
    "        \"numSomersaults\" : str(numSomersaults),\n",
    "        \"numTwists\" : str(numTwists),\n",
    "        \"angleOfEntry\" : str(angleOfEntry),\n",
    "        \"splashIndex\" : str(splashIndex)\n",
    "    }\n",
    "    result_json = json.dumps(result)\n",
    "    print('result', result_json)\n",
    "    return result_json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 5000, app)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be48f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d674d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f6c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
