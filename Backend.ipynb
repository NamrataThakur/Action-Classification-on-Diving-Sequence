{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3593e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.6.0\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grace\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.scimath import sqrt # used for hoF\n",
    "from numpy import arctan2 # used for hoF\n",
    "\n",
    "from scipy import pi, cos, sin # used for HoF\n",
    "from scipy.ndimage import uniform_filter # used for hoF\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "#for i3d extraction\n",
    "from models.i3d.extract_i3d import ExtractI3D\n",
    "from utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3835b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "dive_action_labels  = ['Entry', 'Flight', 'Takeoff']\n",
    "temp_segment_model = None\n",
    "autoscore_model = None\n",
    "somersault_model = None\n",
    "twist_model = None\n",
    "angle_of_entry_model = None\n",
    "splash_model = None\n",
    "linear_regression_model = None\n",
    "folderpath      = 'modelcheckpoints/'\n",
    "i3dextractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a7d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temporal_segment_model():\n",
    "    print('loading temporal segment model')\n",
    "    global temp_segment_model\n",
    "    image_height, image_width = 64, 64\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    model.load_weights(folderpath+\"model_2D.h5\")\n",
    "    temp_segment_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc672abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_autoscore_model():\n",
    "    print('loading autoscore model')\n",
    "    global autoscore_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b44ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_somersault_model():\n",
    "    print('loading somersault model')\n",
    "    global somersault_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc1b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twist_model():\n",
    "    print('loading twist model')\n",
    "    global twist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b61b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_angle_of_entry_model():\n",
    "    print('loading angle of entry model')\n",
    "    global angle_of_entry_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7781db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_splash_model():\n",
    "    print('loading splash model')\n",
    "    global splash_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9753b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linear_regression_model():\n",
    "    print('loading linear regression model')\n",
    "    global linear_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ceb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureDirectoryClean(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    else:\n",
    "        for f in os.listdir(dirpath):\n",
    "            os.remove(os.path.join(dirpath, f))\n",
    "\n",
    "def extractFolderAndFileNameFromAbsPath(absFilePath):\n",
    "    filename_sep = absFilePath.rindex('\\\\')\n",
    "    extension_sep = absFilePath.rindex(\".\")\n",
    "    folder = absFilePath[0: filename_sep]\n",
    "    shortfilename = absFilePath[filename_sep+1:extension_sep]\n",
    "    ext = absFilePath[extension_sep+1:len(absFilePath)]\n",
    "    return folder, shortfilename, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7121b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_temporal_segmentation(vidpath, imgOutputDir):\n",
    "    global temp_segment_model\n",
    "    window_size=3\n",
    "    predicted_label_list = []\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    " \n",
    "    video_reader = cv2.VideoCapture(vidpath)\n",
    " \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    for dive_action_label in dive_action_labels:\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        ensureDirectoryClean(subdir)\n",
    "    \n",
    "    #video_writer = cv2.VideoWriter(imgOutputDir, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (original_video_width, original_video_height))\n",
    "    count=0\n",
    "    image_height, image_width = 64, 64\n",
    "    while True: \n",
    "        count += 1 \n",
    "        status, frame = video_reader.read() \n",
    " \n",
    "        if not status:\n",
    "            break\n",
    "         \n",
    "        # predict frame type (Takeoff/Flight/Entry)\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255 \n",
    "        predicted_labels_probabilities = temp_segment_model.predict(np.expand_dims(normalized_frame, axis = 0))[0] \n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    " \n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "            #print('predicted_labels_probabilities_np : ',predicted_labels_probabilities_np)\n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "            #print('predicted_labels_probabilities_averaged',predicted_labels_probabilities_averaged)\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "            \n",
    "        else: # len(predicted_labels_probabilities_deque) < window_size\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities) \n",
    "        \n",
    "        predicted_label_list.append(predicted_label)\n",
    "        predicted_class_name = dive_action_labels[predicted_label]\n",
    "        #print('predicted_class' , predicted_class_name)\n",
    "        \n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ predicted_class_name \n",
    "        imagename = subdir+\"\\\\\"+(\"frame%04d.jpg\" % count)\n",
    "        #print('write to ', imagename)\n",
    "        cv2.imwrite(imagename, frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    #video_writer.release()\n",
    "    return predicted_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13167e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizeFrameDim [width, height]\n",
    "def createVideo(image_folder, video_folder, divephase, vidname, resizeFrame=False, resizeFrameDim=[64,64]):\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "    if (len(images)==0):\n",
    "        return\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "\n",
    "    height, width, layers = frame.shape\n",
    "    if (resizeFrame == True):\n",
    "        height = resizeFrameDim[1]\n",
    "        width = resizeFrameDim[0]\n",
    "    vidFullName = video_folder+'\\\\'+vidname+\"_\"+divephase+\".mp4\"\n",
    "    print('writing video to ', vidFullName , ' framewidth ', width, ' frameheight ', height)\n",
    "    fps = 25\n",
    "    video = cv2.VideoWriter(vidFullName, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        frame = cv2.imread(os.path.join(image_folder, image))\n",
    "        if (resizeFrame == True):\n",
    "            frame = cv2.resize(frame, (height, width))\n",
    "        video.write(frame)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    return vidFullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3209b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleanUp flag to delete temp folder created for normalizing number of images\n",
    "def createNormalizedVideos(vidpath, imgOutputDir, numImages, cleanUp=True):\n",
    "    video_list = []\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    for dive_action_label in dive_action_labels:\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        subdirNorm = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\N\"+ dive_action_label \n",
    "        ensureDirectoryClean(subdirNorm)\n",
    "        index = {}\n",
    "        files = os.listdir(subdir)\n",
    "        numFiles = len(files)\n",
    "        if (numFiles == 0):\n",
    "            os.rmdir(subdirNorm)\n",
    "            continue\n",
    "        for file in files:\n",
    "            index[file] = 1\n",
    "        if (numFiles < numImages):\n",
    "            diff = numImages - numFiles\n",
    "            count = 0;\n",
    "            while (count < diff):\n",
    "                rand = random.choice(files)\n",
    "                index[rand] = index[rand]+1\n",
    "                count += 1\n",
    "            \n",
    "        elif (numFiles > numImages):\n",
    "            diff = numFiles - numImages\n",
    "            count = 0;\n",
    "            while (count < diff):\n",
    "                rand = random.choice(files)\n",
    "                if (index[rand] > 0):\n",
    "                    index[rand] = index[rand]-1\n",
    "                    count += 1\n",
    "        sortedkeys = list(index.keys())\n",
    "        sortedkeys.sort()\n",
    "        count = 0\n",
    "        for key in sortedkeys:\n",
    "            frame = cv2.imread(subdir+\"\\\\\"+key)\n",
    "            for i in range(index[key]):\n",
    "                count+=1\n",
    "                imagename = subdirNorm+\"\\\\\"+(\"frame%04d.jpg\" % count)\n",
    "                cv2.imwrite(imagename, frame)\n",
    "        #write video to directory\n",
    "        vidFullName = createVideo(subdirNorm, imgOutputDir+\"\\\\\"+shortfilename, \"N\"+dive_action_label, shortfilename,\n",
    "                                 resizeFrame=True, resizeFrameDim=[64,64])\n",
    "        video_list.append(vidFullName)\n",
    "        \n",
    "        #cleanup\n",
    "        if(cleanUp == True):\n",
    "            for f in os.listdir(subdirNorm):\n",
    "                os.remove(subdirNorm+\"\\\\\"+f)\n",
    "            os.rmdir(subdirNorm) \n",
    "            \n",
    "    return video_list\n",
    "#createNormalizedVideos(\"C:\\\\Users\\\\Grace\\\\MTech Jupyter\\\\Intelligent Sensing Systems\\\\PracticeMod\\\\testdive.mp4\", \n",
    "#                       '.\\\\images', 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afab8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videosAreComplete(list_videos):\n",
    "    hasTakeoff = False\n",
    "    hasFlight = False\n",
    "    hasEntry = False\n",
    "    for video in list_videos:\n",
    "        if ('Takeoff' in video):\n",
    "            hasTakeoff = True\n",
    "        elif ('Flight' in video):\n",
    "            hasFlight = True\n",
    "        elif ('Entry' in video):\n",
    "            hasEntry = True\n",
    "    return hasEntry and hasTakeoff and hasFlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9561a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractI3DFeatures(vidpaths):\n",
    "    global i3dextractor\n",
    "    if (i3dextractor == None):\n",
    "        args = OmegaConf.load(build_cfg_path('i3d'))\n",
    "        args.stack_size = 32\n",
    "        args.step_size = 32\n",
    "        # args.extraction_fps = 25\n",
    "        args.device='cpu'#force to cpu to prevent OOM error\n",
    "        args.flow_type = 'raft' # 'pwc' is not supported on Google Colab (cupy version mismatch)\n",
    "        i3dextractor = ExtractI3D(args)\n",
    "    rgb_features = [] \n",
    "    for vidpath in vidpaths:\n",
    "        print(f'Extracting for {vidpath}')\n",
    "        feature_dict = i3dextractor.extract(vidpath)\n",
    "        vidname = vidpath.replace('.mp4','')\n",
    "        for k, v in feature_dict.items():\n",
    "            if (k=='rgb'): # or k=='flow'):\n",
    "                rgb_features.append(v)\n",
    "    i3d_features = np.concatenate(rgb_features, axis=None)\n",
    "    return i3d_features.reshape(1, 3072)\n",
    "#extractI3DFeatures(['.\\\\images\\\\testdive\\\\testdive_NFlight.mp4',\n",
    "#                     '.\\\\images\\\\testdive\\\\testdive_NTakeoff.mp4',\n",
    "#                       '.\\\\images\\\\testdive\\\\testdive_NTakeoff.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7344dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_autoscore(vidpath, imgOutputDir):\n",
    "    print('predict autoscore')\n",
    "    global autoscore_model\n",
    "    numImages=33\n",
    "    norm_vidpaths = createNormalizedVideos(vidpath, imgOutputDir, numImages)\n",
    "    # check that there are 3 videos, else decline to proceed\n",
    "    if (videosAreComplete(norm_vidpaths)==False):\n",
    "        print('videos are incomplete! missing either entry, flight or takeoff phase')\n",
    "        return -1\n",
    "    videos_features = extractI3DFeatures(norm_vidpaths)\n",
    "    if (autoscore_model == None):\n",
    "        autoscore_model = load_model('modelcheckpoints/fullyconnected_ID1024D512D1_0.01.hdf5')\n",
    "    score = autoscore_model.predict(videos_features)\n",
    "    for video in norm_vidpaths:\n",
    "        os.remove(video)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8686d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_somersaults(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92cbae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_twists(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d07001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_angle_of_entry(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f50c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_splash_index(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aae1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d589b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processVideo(vidpath):\n",
    "    print('processing ', vidpath)\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    predict_temporal_segmentation(vidpath, '.\\\\images')\n",
    "    autoscore = predict_autoscore(vidpath, '.\\\\images')\n",
    "    numSomersaults = predict_num_somersaults(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    numTwists = predict_num_twists(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    angleOfEntry = predict_angle_of_entry(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    splashIndex = predict_splash_index(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    final_score = predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex)\n",
    "    print('autoscore: ', autoscore, \n",
    "          ', numSomersaults: ', numSomersaults, \n",
    "          ', numTwists: ', numTwists,\n",
    "          ', angleOfEntry: ', angleOfEntry,\n",
    "          ', splashIndex: ', splashIndex,\n",
    "          ', final_score: ', final_score)\n",
    "    return final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a3669c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_temporal_segment_model()\n",
    "    load_autoscore_model()\n",
    "    load_somersault_model()\n",
    "    load_twist_model()\n",
    "    load_angle_of_entry_model()\n",
    "    load_splash_model()\n",
    "    load_linear_regression_model()\n",
    "    final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex = processVideo(\".\\\\testdive5.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b9b6731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading temporal segment model\n",
      "loading autoscore model\n",
      "loading somersault model\n",
      "loading twist model\n",
      "loading angle of entry model\n",
      "loading splash model\n",
      "loading linear regression model\n",
      "processing  .\\testdive5.mp4\n",
      "predict autoscore\n",
      "writing video to  .\\images\\testdive5\\testdive5_NEntry.mp4  framewidth  64  frameheight  64\n",
      "writing video to  .\\images\\testdive5\\testdive5_NFlight.mp4  framewidth  64  frameheight  64\n",
      "writing video to  .\\images\\testdive5\\testdive5_NTakeoff.mp4  framewidth  64  frameheight  64\n",
      "using device  cpu\n",
      "Extracting for .\\images\\testdive5\\testdive5_NEntry.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grace\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting for .\\images\\testdive5\\testdive5_NFlight.mp4\n",
      "Extracting for .\\images\\testdive5\\testdive5_NTakeoff.mp4\n",
      "autoscore:  [[0.48972556]] , numSomersaults:  -1 , numTwists:  -1 , angleOfEntry:  -1 , splashIndex:  -1 , final_score:  -1\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe8060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48595aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
