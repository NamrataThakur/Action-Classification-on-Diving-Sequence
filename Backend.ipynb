{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3593e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.6.0\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.scimath import sqrt # used for hoF\n",
    "from numpy import arctan2 # used for hoF\n",
    "\n",
    "from scipy import pi, cos, sin # used for HoF\n",
    "from scipy.ndimage import uniform_filter # used for hoF\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "#for i3d extraction\n",
    "from models.i3d.extract_i3d import ExtractI3D\n",
    "from utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3835b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "dive_action_labels  = ['Entry', 'Flight', 'Takeoff']\n",
    "temp_segment_model = None\n",
    "autoscore_model = None\n",
    "ss_twist_classifier_model = None\n",
    "somersault_model = None\n",
    "twist_model = None\n",
    "angle_of_entry_model = None\n",
    "splash_model = None\n",
    "linear_regression_model = None\n",
    "folderpath      = 'modelcheckpoints/'\n",
    "i3dextractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6a7d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temporal_segment_model():\n",
    "    print('loading temporal segment model')\n",
    "    global temp_segment_model\n",
    "    image_height, image_width = 64, 64\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    model.load_weights(folderpath+\"model_2D.h5\")\n",
    "    temp_segment_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc672abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_autoscore_model():\n",
    "    print('loading autoscore model')\n",
    "    global autoscore_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22f1eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ss_twist_classifier_model():\n",
    "    print('loading ss_twist_classifier model')\n",
    "    global ss_twist_classifier_model\n",
    "    image_height, image_width = 64, 64\n",
    "    optim = tf.keras.optimizers.Adam(0.0001)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=optim, metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    model.load_weights(folderpath+\"model_flightClassify_2D_3.h5\")\n",
    "    ss_twist_classifier_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b44ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_somersault_model():\n",
    "    print('loading somersault model')\n",
    "    global somersault_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc1b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twist_model():\n",
    "    print('loading twist model')\n",
    "    global twist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02b61b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_angle_of_entry_model():\n",
    "    print('loading angle of entry model')\n",
    "    global angle_of_entry_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7781db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_splash_model():\n",
    "    print('loading splash model')\n",
    "    global splash_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9753b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linear_regression_model():\n",
    "    print('loading linear regression model')\n",
    "    global linear_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27ceb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureDirectoryClean(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    else:\n",
    "        for f in os.listdir(dirpath):\n",
    "            os.remove(os.path.join(dirpath, f))\n",
    "\n",
    "def extractFolderAndFileNameFromAbsPath(absFilePath):\n",
    "    filename_sep = absFilePath.rindex('\\\\')\n",
    "    extension_sep = absFilePath.rindex(\".\")\n",
    "    folder = absFilePath[0: filename_sep]\n",
    "    shortfilename = absFilePath[filename_sep+1:extension_sep]\n",
    "    ext = absFilePath[extension_sep+1:len(absFilePath)]\n",
    "    return folder, shortfilename, ext\n",
    "\n",
    "def extractEventNoAndDiveNo(folderPath):\n",
    "    tokens = folderPath.split(\"\\\\\")\n",
    "    diveno = tokens[len(tokens)-1]\n",
    "    eventno = tokens[len(tokens)-2]\n",
    "    return eventno, diveno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb7121b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_temporal_segmentation(vidpath, imgOutputDir):\n",
    "    global temp_segment_model\n",
    "    window_size=3\n",
    "    predicted_label_list = []\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    " \n",
    "    video_reader = cv2.VideoCapture(vidpath)\n",
    " \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    for dive_action_label in dive_action_labels:\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        ensureDirectoryClean(subdir)\n",
    "    \n",
    "    #video_writer = cv2.VideoWriter(imgOutputDir, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (original_video_width, original_video_height))\n",
    "    count=0\n",
    "    image_height, image_width = 64, 64\n",
    "    while True: \n",
    "        count += 1 \n",
    "        status, frame = video_reader.read() \n",
    " \n",
    "        if not status:\n",
    "            break\n",
    "         \n",
    "        # predict frame type (Takeoff/Flight/Entry)\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255 \n",
    "        predicted_labels_probabilities = temp_segment_model.predict(np.expand_dims(normalized_frame, axis = 0))[0] \n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    " \n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "            #print('predicted_labels_probabilities_np : ',predicted_labels_probabilities_np)\n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "            #print('predicted_labels_probabilities_averaged',predicted_labels_probabilities_averaged)\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "            \n",
    "        else: # len(predicted_labels_probabilities_deque) < window_size\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities) \n",
    "        \n",
    "        predicted_label_list.append(predicted_label)\n",
    "        predicted_class_name = dive_action_labels[predicted_label]\n",
    "        #print('predicted_class' , predicted_class_name)\n",
    "        \n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ predicted_class_name \n",
    "        imagename = subdir+\"\\\\\"+(\"frame%04d.jpg\" % count)\n",
    "        #print('write to ', imagename)\n",
    "        cv2.imwrite(imagename, frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    #video_writer.release()\n",
    "    return predicted_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13167e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizeFrameDim [width, height]\n",
    "def createVideo(image_folder, video_folder, divephase, vidname, resizeFrame=False, resizeFrameDim=[64,64]):\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "    if (len(images)==0):\n",
    "        return\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "\n",
    "    height, width, layers = frame.shape\n",
    "    if (resizeFrame == True):\n",
    "        height = resizeFrameDim[1]\n",
    "        width = resizeFrameDim[0]\n",
    "    vidFullName = video_folder+'\\\\'+vidname+\"_\"+divephase+\".mp4\"\n",
    "    print('writing video to ', vidFullName , ' framewidth ', width, ' frameheight ', height)\n",
    "    fps = 25\n",
    "    video = cv2.VideoWriter(vidFullName, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), fps, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        frame = cv2.imread(os.path.join(image_folder, image))\n",
    "        if (resizeFrame == True):\n",
    "            frame = cv2.resize(frame, (height, width))\n",
    "        video.write(frame)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    return vidFullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3209b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleanUp flag to delete temp folder created for normalizing number of images\n",
    "def createNormalizedVideos(vidpath, imgOutputDir, numImages, cleanUp=True):\n",
    "    video_list = []\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    for dive_action_label in dive_action_labels:\n",
    "        subdir = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\\"+ dive_action_label \n",
    "        subdirNorm = imgOutputDir+\"\\\\\"+shortfilename+\"\\\\N\"+ dive_action_label \n",
    "        ensureDirectoryClean(subdirNorm)\n",
    "        index = {}\n",
    "        files = os.listdir(subdir)\n",
    "        numFiles = len(files)\n",
    "        if (numFiles == 0):\n",
    "            os.rmdir(subdirNorm)\n",
    "            continue\n",
    "        for file in files:\n",
    "            index[file] = 1\n",
    "        if (numFiles < numImages):\n",
    "            diff = numImages - numFiles\n",
    "            count = 0;\n",
    "            while (count < diff):\n",
    "                rand = random.choice(files)\n",
    "                index[rand] = index[rand]+1\n",
    "                count += 1\n",
    "            \n",
    "        elif (numFiles > numImages):\n",
    "            diff = numFiles - numImages\n",
    "            count = 0;\n",
    "            while (count < diff):\n",
    "                rand = random.choice(files)\n",
    "                if (index[rand] > 0):\n",
    "                    index[rand] = index[rand]-1\n",
    "                    count += 1\n",
    "        sortedkeys = list(index.keys())\n",
    "        sortedkeys.sort()\n",
    "        count = 0\n",
    "        for key in sortedkeys:\n",
    "            frame = cv2.imread(subdir+\"\\\\\"+key)\n",
    "            for i in range(index[key]):\n",
    "                count+=1\n",
    "                imagename = subdirNorm+\"\\\\\"+(\"frame%04d.jpg\" % count)\n",
    "                cv2.imwrite(imagename, frame)\n",
    "        #write video to directory\n",
    "        vidFullName = createVideo(subdirNorm, imgOutputDir+\"\\\\\"+shortfilename, \"N\"+dive_action_label, shortfilename,\n",
    "                                 resizeFrame=True, resizeFrameDim=[64,64])\n",
    "        video_list.append(vidFullName)\n",
    "        \n",
    "        #cleanup\n",
    "        if(cleanUp == True):\n",
    "            for f in os.listdir(subdirNorm):\n",
    "                os.remove(subdirNorm+\"\\\\\"+f)\n",
    "            os.rmdir(subdirNorm) \n",
    "            \n",
    "    return video_list\n",
    "#createNormalizedVideos(\"C:\\\\Users\\\\Grace\\\\MTech Jupyter\\\\Intelligent Sensing Systems\\\\PracticeMod\\\\testdive.mp4\", \n",
    "#                       '.\\\\images', 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afab8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videosAreComplete(list_videos):\n",
    "    hasTakeoff = False\n",
    "    hasFlight = False\n",
    "    hasEntry = False\n",
    "    for video in list_videos:\n",
    "        if ('Takeoff' in video):\n",
    "            hasTakeoff = True\n",
    "        elif ('Flight' in video):\n",
    "            hasFlight = True\n",
    "        elif ('Entry' in video):\n",
    "            hasEntry = True\n",
    "    return hasEntry and hasTakeoff and hasFlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9561a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractI3DFeatures(vidpaths):\n",
    "    global i3dextractor\n",
    "    if (i3dextractor == None):\n",
    "        args = OmegaConf.load(build_cfg_path('i3d'))\n",
    "        args.stack_size = 32\n",
    "        args.step_size = 32\n",
    "        # args.extraction_fps = 25\n",
    "        args.device='cpu'#force to cpu to prevent OOM error\n",
    "        args.flow_type = 'raft' # 'pwc' is not supported on Google Colab (cupy version mismatch)\n",
    "        i3dextractor = ExtractI3D(args)\n",
    "    rgb_features = [] \n",
    "    for vidpath in vidpaths:\n",
    "        print(f'Extracting for {vidpath}')\n",
    "        feature_dict = i3dextractor.extract(vidpath)\n",
    "        vidname = vidpath.replace('.mp4','')\n",
    "        for k, v in feature_dict.items():\n",
    "            if (k=='rgb'): # or k=='flow'):\n",
    "                rgb_features.append(v)\n",
    "    i3d_features = np.concatenate(rgb_features, axis=None)\n",
    "    return i3d_features.reshape(1, 3072)\n",
    "#extractI3DFeatures(['.\\\\images\\\\testdive\\\\testdive_NFlight.mp4',\n",
    "#                     '.\\\\images\\\\testdive\\\\testdive_NTakeoff.mp4',\n",
    "#                       '.\\\\images\\\\testdive\\\\testdive_NTakeoff.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7344dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_autoscore(vidpath, imgOutputDir):\n",
    "    print('predict autoscore')\n",
    "    global autoscore_model\n",
    "    numImages=33\n",
    "    norm_vidpaths = createNormalizedVideos(vidpath, imgOutputDir, numImages)\n",
    "    # check that there are 3 videos, else decline to proceed\n",
    "    if (videosAreComplete(norm_vidpaths)==False):\n",
    "        print('videos are incomplete! missing either entry, flight or takeoff phase')\n",
    "        return -1\n",
    "    videos_features = extractI3DFeatures(norm_vidpaths)\n",
    "    if (autoscore_model == None):\n",
    "        autoscore_model = load_model('modelcheckpoints/fullyconnected_ID1024D512D1_0.01.hdf5')\n",
    "    score = autoscore_model.predict(videos_features)\n",
    "    for video in norm_vidpaths:\n",
    "        os.remove(video)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a851b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ss_or_twist(imgFolder):\n",
    "    print('predict ss or twist')\n",
    "    global ss_twist_classifier_model\n",
    "    window_size = 1\n",
    "    images = sorted(os.listdir(imgFolder))\n",
    "    predicted_label_list = []\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "    eventno, diveno = extractEventNoAndDiveNo(imgFolder)\n",
    "    numTwistFrames = 0\n",
    "    numSSFrames = 0\n",
    "    fps = 25\n",
    "    frame = cv2.imread(imgFolder+\"\\\\\"+images[0])\n",
    "    image_height = frame.shape[0]\n",
    "    image_width = frame.shape[1]\n",
    "    videoSS = cv2.VideoWriter(imgFolder+eventno+\"_\"+diveno+\"_ss.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (image_width,image_height))\n",
    "    videoTW = cv2.VideoWriter(imgFolder+eventno+\"_\"+diveno+\"_tw.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (image_width,image_height))\n",
    "    for i in range(len(images)):\n",
    "        frame = cv2.imread(imgFolder+\"\\\\\"+images[i])\n",
    "        \n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (64,64))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    " \n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = ss_twist_classifier_model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    " \n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    " \n",
    "        # Assuring that the Deque is completely filled before starting the averaging process\n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    " \n",
    "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "            #print('predicted_labels_probabilities_np : ',predicted_labels_probabilities_np)\n",
    " \n",
    "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "            #print('predicted_labels_probabilities_averaged',predicted_labels_probabilities_averaged)\n",
    " \n",
    "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    " \n",
    "        else: # len(predicted_labels_probabilities_deque) < window_size\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities) \n",
    " \n",
    "\n",
    "        # Accessing The Class Name using predicted label.\n",
    "        #predicted_class_name = dive_action_labels[predicted_label]\n",
    "        \n",
    "        if (predicted_label == 0): #SS\n",
    "            numSSFrames += 1\n",
    "            videoSS.write(frame)\n",
    "            predicted_label_list.append('SS')\n",
    "        elif (predicted_label == 1):\n",
    "            numTwistFrames += 1\n",
    "            videoTW.write(frame)\n",
    "            predicted_label_list.append('TW')\n",
    "    print('numSSFrames ', numSSFrames)\n",
    "    print('numTwistFrames ', numTwistFrames)\n",
    "    print(predicted_label_list)\n",
    "    cv2.destroyAllWindows()\n",
    "    videoSS.release()\n",
    "    videoTW.release()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8686d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_somersaults(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92cbae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_num_twists(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98d07001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_angle_of_entry(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f50c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_splash_index(imgFolder):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7aae1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex):\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d589b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processVideo(vidpath):\n",
    "    print('processing ', vidpath)\n",
    "    folder, shortfilename, _ = extractFolderAndFileNameFromAbsPath(vidpath)\n",
    "    predict_temporal_segmentation(vidpath, '.\\\\images')\n",
    "    autoscore = predict_autoscore(vidpath, '.\\\\images')\n",
    "    predict_ss_or_twist(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    numSomersaults = predict_num_somersaults(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    numTwists = predict_num_twists(\".\\\\images\\\\\"+shortfilename+\"\\\\Flight\")\n",
    "    angleOfEntry = predict_angle_of_entry(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    splashIndex = predict_splash_index(\".\\\\images\\\\\"+shortfilename+\"\\\\Entry\")\n",
    "    final_score = predict_final_score(autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex)\n",
    "    print('autoscore: ', autoscore, \n",
    "          ', numSomersaults: ', numSomersaults, \n",
    "          ', numTwists: ', numTwists,\n",
    "          ', angleOfEntry: ', angleOfEntry,\n",
    "          ', splashIndex: ', splashIndex,\n",
    "          ', final_score: ', final_score)\n",
    "    return final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a3669c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_temporal_segment_model()\n",
    "    load_autoscore_model()\n",
    "    load_ss_twist_classifier_model()\n",
    "    load_somersault_model()\n",
    "    load_twist_model()\n",
    "    load_angle_of_entry_model()\n",
    "    load_splash_model()\n",
    "    load_linear_regression_model()\n",
    "    final_score, autoscore, numSomersaults, numTwists, angleOfEntry, splashIndex = processVideo(\".\\\\testdive5.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b9b6731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading temporal segment model\n",
      "loading ss_twist_classifier model\n",
      "loading somersault model\n",
      "loading twist model\n",
      "loading angle of entry model\n",
      "loading splash model\n",
      "loading linear regression model\n",
      "processing  .\\testdive5.mp4\n",
      "predict ss or twist\n",
      "numSSFrames  50\n",
      "numTwistFrames  32\n",
      "[1, 'TW', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 1, 'TW', 1, 'TW', 0, 'SS', 1, 'TW', 0, 'SS', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 1, 'TW', 0, 'SS', 0, 'SS', 1, 'TW', 0, 'SS', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 1, 'TW', 1, 'TW', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS', 0, 'SS']\n",
      "autoscore:  0 , numSomersaults:  -1 , numTwists:  -1 , angleOfEntry:  -1 , splashIndex:  -1 , final_score:  -1\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe8060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48595aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
